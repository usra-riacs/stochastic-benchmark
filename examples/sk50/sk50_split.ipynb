{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')\n",
    "import stochastic_benchmark as SB\n",
    "\n",
    "from wishart_ws import postprocess_linear, postprocess_random\n",
    "\n",
    "# from collections import defaultdict\n",
    "# import dill\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import os\n",
    "# import pandas as pd\n",
    "# import glob\n",
    "# import seaborn as sns\n",
    "# import seaborn.objects as so\n",
    "\n",
    "import bootstrap\n",
    "# import df_utils\n",
    "import interpolate\n",
    "import random_exploration\n",
    "import sequential_exploration\n",
    "import names\n",
    "import stats\n",
    "import success_metrics\n",
    "# import training\n",
    "from utils_ws import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up basic information \n",
    "alpha = '0.5'\n",
    "# path to working directory\n",
    "here = os.getcwd()\n",
    "parameter_names = ['sweeps', 'replicas', 'pcold', 'phot']\n",
    "instance_cols = ['instance'] #indicates how instances should be grouped, default is ['instance']\n",
    "\n",
    "## Response information \n",
    "response_key = 'PerfRatio' # Column with the response, default is 'PerfRatio'\n",
    "response_dir = 1 # whether we want to maximize (1) or minimize (-1), default is 1\n",
    "\n",
    "## Optimizations informations\n",
    "recover = True #Whether we want to read dataframes when available, default is True\n",
    "reduce_mem = True #Whether we want to segment bootstrapping and interpolation to reduce memory usage, default is True\n",
    "smooth = True #Whether virtual best should be monontonized, default is True\n",
    "\n",
    "sb = SB.stochastic_benchmark(parameter_names, here, instance_cols, response_key, response_dir, recover, reduce_mem, smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up bootstrapped parameters\n",
    "shared_args = {'response_col':'Energy',\\\n",
    "                  'resource_col':'MeanTime',\\\n",
    "                  'response_dir':-1,\\\n",
    "                  'confidence_level':68,\\\n",
    "                  'random_value':0.}\n",
    "metric_args = {}\n",
    "metric_args['Response'] = {'opt_sense':-1}\n",
    "metric_args['SuccessProb'] = {'gap':1.0, 'response_dir':-1}\n",
    "metric_args['RTT'] = {'fail_value': np.nan, 'RTT_factor':1.,\\\n",
    "                        'gap':1.0, 's':0.99}\n",
    "\n",
    "def update_rules(self, df):  #These update the bootstrap parameters for each group \n",
    "    GTMinEnergy = df['GTMinEnergy'].iloc[0] \n",
    "    self.shared_args['best_value'] = GTMinEnergy #update best value for each instance\n",
    "    self.metric_args['RTT']['RTT_factor'] = df['MeanTime'].iloc[0]\n",
    "\n",
    "agg = 'count' #aggregated column\n",
    "#success metric we want to calculate\n",
    "sms = [success_metrics.Response,\n",
    "        success_metrics.PerfRatio,\n",
    "        success_metrics.InvPerfRatio,\n",
    "        success_metrics.SuccessProb,\n",
    "        success_metrics.Resource,\n",
    "        success_metrics.RTT]\n",
    "boots_range = range(50, 1001, 50) \n",
    "ssOrderCols = ['warmstart={}_hpo_order={}'.format(h, hpo_trial) for h in [0, 1] for hpo_trial in range(10)]\n",
    "bsParams = bootstrap.BootstrapParameters(shared_args=shared_args,\n",
    "                                            update_rule=update_rules,\n",
    "                                            agg=agg,\n",
    "                                            metric_args=metric_args,\n",
    "                                            success_metrics=sms,\n",
    "                                            keep_cols=ssOrderCols)\n",
    "bs_iter_class = bootstrap.BSParams_range_iter()\n",
    "bsparams_iter = bs_iter_class(bsParams, boots_range)\n",
    "\n",
    "#How names should be parsed from raw filesnames\n",
    "def group_name_fcn(raw_filename):\n",
    "    raw_filename = os.path.basename(raw_filename)\n",
    "    start_idx = raw_filename.index('inst')\n",
    "    end_idx = raw_filename.index('.')\n",
    "    return raw_filename[start_idx: end_idx]\n",
    "\n",
    "# Run bootstrap\n",
    "sb.run_Bootstrap(bsparams_iter, group_name_fcn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate \n",
    "def resource_fcn(df):\n",
    "    return df['sweeps'] * df['replicas'] * df['boots']\n",
    "iParams = interpolate.InterpolationParameters(resource_fcn,\n",
    "                                                    parameters=parameter_names,\n",
    "                                                    ignore_cols = ssOrderCols)\n",
    "\n",
    "sb.run_Interpolate(iParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Stats computations\n",
    "train_test_split = 0.8\n",
    "metrics = ['Response', 'RTT', 'PerfRatio', 'SuccProb', 'MeanTime', 'InvPerfRatio']\n",
    "stParams = stats.StatsParameters(metrics=metrics, stats_measures=[stats.Median()])\n",
    "\n",
    "sb.run_Stats(stParams, train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not want to run step by step, initialize parameters as above and run initAll\n",
    "#sb.initAll(bsparams_iter, iParams, stParams, resource_fcn, train_test_split, group_name_fcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run virtual best baseline\n",
    "sb.run_baseline()\n",
    "sb.run_ProjectionExperiment('TrainingStats', lambda x : postprocess_linear(x), 'linear')\n",
    "sb.run_ProjectionExperiment('TrainingResults', lambda x : postprocess_linear(x), 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up Random search parameters and sequential search paramters\n",
    "\n",
    "# Make sure search budgets align with the baselines - needed for the distance\n",
    "recipes,_ = sb.baseline.evaluate()\n",
    "recipes.reset_index(inplace=True)\n",
    "resource_values = list(recipes['resource'])\n",
    "budgets = [i*10**j for i in [1, 1.5, 2, 3, 5, 7]\n",
    "            for j in [3, 4, 5]] + [1e6]\n",
    "budgets = np.unique([take_closest(resource_values, b) for b in budgets])\n",
    "\n",
    "restrict='grid_search'\n",
    "\n",
    "# which columns determin the order in sequential search experiments\n",
    "ssOrderCols0 = ['warmstart=0_hpo_order={}'.format(hpo_trial) for hpo_trial in range(10)] \n",
    "ssOrderCols1 = ['warmstart=1_hpo_order={}'.format(hpo_trial) for hpo_trial in range(10)] \n",
    "\n",
    "\n",
    "# Which column you are optimizing. Different from initialization b/c aggregated metrics include the name\n",
    "key = names.param2filename({'Key': 'PerfRatio', 'Metric':'median'}, '')\n",
    "\n",
    "rsParams = random_exploration.RandomSearchParameters(\n",
    "    budgets=budgets,\n",
    "    parameter_names=parameter_names,\n",
    "    key=key)\n",
    "    \n",
    "ssParams0 = sequential_exploration.SequentialSearchParameters(\n",
    "    budgets=budgets,\n",
    "    order_cols=ssOrderCols0,\n",
    "    parameter_names=parameter_names,\n",
    "    key='Key=PerfRatio')\n",
    "\n",
    "ssParams1 = sequential_exploration.SequentialSearchParameters(\n",
    "    budgets=budgets,\n",
    "    order_cols=ssOrderCols1,\n",
    "    parameter_names=parameter_names,\n",
    "    key='Key=PerfRatio')\n",
    "\n",
    "sb.run_RandomSearchExperiment(rsParams, postprocess=postprocess_random, postprocess_name='custom')\n",
    "sb.run_SequentialSearchExperiment(ssParams0, id_name='cold', postprocess=postprocess_random, postprocess_name='custom')\n",
    "sb.run_SequentialSearchExperiment(ssParams1, id_name='warm', postprocess=postprocess_random, postprocess_name='custom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.initPlotting()\n",
    "sb.plots.set_xlims((10**3,  10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = sb.plots.plot_performance()\n",
    "# axs.set_ylim(0.93, 1.001)\n",
    "# keep pink static, cold start\n",
    "# fig.savefig('Performance.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = sb.plots.plot_parameters_distance()\n",
    "axs.set_yscale('log')\n",
    "# p.savefig('Parameters_distance.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = sb.plots.plot_meta_parameters()\n",
    "for experiment,v in figs.items():\n",
    "    for param, fig in v.items():\n",
    "        # if param == 'tau':\n",
    "        #     ax = p.axes[0]\n",
    "            # ax.set_yscale('log')\n",
    "        #Tau on log scale, frac on linear, definitions for axis\n",
    "        fig.savefig('{}_metaparameters={}.pdf'.format(experiment, param))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = sb.plots.plot_parameters_separate()\n",
    "for param, axs in axes.items():\n",
    "    if param == 'sweeps':\n",
    "        axs.set_ylim(1, 50)\n",
    "    # fig.savefig('Recommended_parameter={}_scale={}.pdf'.format(param, sb.plots.xscale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = sb.plots.plot_parameters_together()\n",
    "for param, axs in axes.items():\n",
    "    if param == 'sweeps':\n",
    "        axs.set_ylim(1, 50)\n",
    "# fig.savefig('Recommended_allparams_scale={}.pdf'.format(sb.plots.xscale))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('SB')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c746e22876cc9517b5ed57bd6907ecbc9cc9ab46f774569dcfc1ac4f0995eba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
